{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABLCAYAAABz9YPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAqRJREFUeJzt3TFqlEEcxuH5shpdjaBoWhW0MloZsLP0KHsMD+IBvEkaiZ1dQLARhIAgMSQQMzY2Nq4hDJNv3ufpAlO8f7b5hQ1kqrUWAIBUG70HAAD0JIYAgGhiCACIJoYAgGhiCACIJoYAgGhiCACIJoYAgGhiCACIdm3dg2maVqWUVSmlLDcWLx8vt5qP6mVzed57QlOL22s/7tmabt3sPaGtG2Pfd74x9u9lp7/Oek9o6uhs3M/v6HTqPaGpk+NF7wlNHX89OKy1bq97N13k33E827pb3794falhV9nDnZPeE5q68+p+7wnNLHaf9p7Q1PRkp/eEpn4uN3tPaOrzj++9JzS1923cWN/7cr33hKYO9u/1ntDUh7dvPtZad9e9GzfnAQD+gxgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKKJIQAgmhgCAKJNtdZ/P5imVSll9efH56WUT61HdfSglHLYe0QjI99Wivvmzn3zNfJtpbhv7h7VWrfXPVobQ389nqb9WuvupWZdYSPfN/Jtpbhv7tw3XyPfVor7UviaDACIJoYAgGgXjaF3TVZcHSPfN/Jtpbhv7tw3XyPfVor7Ilzob4YAAEbjazIAIJoYAgCiiSEAIJoYAgCiiSEAINpvwl5xiUXkRHYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABLCAYAAABz9YPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAqlJREFUeJzt3T9LlmEYxuHryUwjF0ELCopKmqJF175Ic/hx+gB9mOZAoyVairagwK2U7N/d0tLSi8jN7fucx7EJ93Be4PCDR3BqrRUAQKpLowcAAIwkhgCAaGIIAIgmhgCAaGIIAIgmhgCAaGIIAIgmhgCAaGIIAIh2edGDaZr2q2q/qmp1Wt3dvLLVfdQoaxvroyd0tXbtyugJ3axdne9tVVWrayujJ3TVVn6PntDV6a/T0RO6+vrjePSEbr58m+9tVVXHJ/P+3fz5+eSotba96N10ln/HcWP9Znty++m5hl1k9x4/GD2hq/u7d0dP6Gbn0a3RE7q6vrM5ekJX3zdORk/o6sPxu9ETunr58XD0hG5evD0YPaGrg9fvR0/o6tOzw1ettb1F73wmAwCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAINrUWvv/g2nar6r9vz8+rKo3vUcNtFVVR6NHdDLn26rct+zct7zmfFuV+5bdndba9qJHC2Pon8fTdNha2zvXrAtszvfN+bYq9y079y2vOd9W5b4UPpMBANHEEAAQ7awx9LzLiotjzvfN+bYq9y079y2vOd9W5b4IZ/qbIQCAufGZDACIJoYAgGhiCACIJoYAgGhiCACI9gd5pXeJZZU+CgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABLCAYAAABz9YPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAq1JREFUeJzt3T9qVFEYxuHvJhmIoiAaCxW0FCHYmN4NuAir2YCr0Y3YuAFBRcRKECxEEFIJjn+iOTY2Ng4hHE7mvs/TBU7xflV+cAOZWmsFAJBqa/QAAICRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRdtY9mKZpWVXLqqrdWty7uXOl+6hRFpfOjZ7Q1c7F3dETutk+txg9oa/F9ugFXR1v/R49oauj49XoCV2tfn0ZPaGb1Y+voyd09e370egJXX35+POwtXZ13bvpJP+O4/biWnu89/A0u8606w/2R0/o6vL9O6MndHPx7vXRE7qablwYPaGr1fn5/jKtqvr07fXoCV29+fxs9IRuXr1/PnpCV2/ffRo9oaunjz68bK0drHvnMxkAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRptba/x9M07Kqln9/3K+qt71HDbRXVYejR3Qy59uq3Lfp3Le55nxblfs23a3W2tV1j9bG0D+Pp+lFa+3gVLPOsDnfN+fbqty36dy3ueZ8W5X7UvhMBgBEE0MAQLSTxtCTLivOjjnfN+fbqty36dy3ueZ8W5X7Ipzob4YAAObGZzIAIJoYAgCiiSEAIJoYAgCiiSEAINofC4t3iRMat/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABLCAYAAABz9YPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAp9JREFUeJzt3T9LlWEcx+HfYxaBa6615dKUvqbzLnobDb2bpghqsimIGiTJjIgo/xz1bmlp6SDycHvu73Vtwj38vot88IhOrbUCAEi10fsAAICexBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRxBAAEE0MAQDRNlc9mKZpUVWLqqqtrfu7j3cezn5UL8urq94nzOps4Hm/llPvE2Z1cjn2vrOLsfctz8f+S//T6UXvE2YznV/2PmFWV8tl7xNmtTz5fNxa2171brrOv+N4urvTXr56fqPDbrOj09+9T5jVx593ep8wm9df7/Y+YVb73+/1PmFWH47G/iH1l4NxY6GqavP9t94nzGbj04/eJ8zq7PCw9wmzOth/9ra1trfq3djfgQAAVhBDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEC0qbX2/wfTtKiqxd8vn1TVu7mP6uhBVR33PmImI2+rsm/d2be+Rt5WZd+6e9Ra2171aGUM/fN4mt601vZudNYtNvK+kbdV2bfu7FtfI2+rsi+Fj8kAgGhiCACIdt0YejHLFbfHyPtG3lZl37qzb32NvK3KvgjX+p0hAIDR+JgMAIgmhgCAaGIIAIgmhgCAaGIIAIj2B2t9hYmzF97vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABLCAYAAABz9YPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAqlJREFUeJzt3T1qlFEYhuH3i8bEfxADgopNGkWw0MpOsHUbswwX4BJchTuwFy2ENCkUBbEKqIjEQcKxsbFxCHI4me+5ri5wiudtws1MIFNrrQAAUm2MHgAAMJIYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAIJoYAgCiiSEAINrpVQ+maVpU1aKqautU3b9xaeo+apTtrXm34ZlzF0ZP6GZj+/LoCV21zYujJ3R1VJujJ3S1XB6NntDV8vDX6AndHP5Yjp7Q1c/v877v6/LzQWttZ9W76Tj/jmP3ykZ79ni+v7Tu7J4fPaGrm/cejp7QzdnbT0ZP6Oro+qPRE7r6cnRt9ISuPn74NnpCV/tvP42e0M3eq/ejJ3S1/3Le97149/RNa+3Bqnfz/igEAGAFMQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARBNDAEA0MQQARJtaa/9+ME2Lqlr8+fFuVe31HjXQ1ao6GD2ikznfVuW+dee+9TXn26rct+5utdZ2Vj1aGUN/PZ6m1621B/816wSb831zvq3KfevOfetrzrdVuS+Fr8kAgGhiCACIdtwYet5lxckx5/vmfFuV+9ad+9bXnG+rcl+EY/3NEADA3PiaDACIJoYAgGhiCACIJoYAgGhiCACI9hskrHiJkdfrLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "from config import api_key_tmdb\n",
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "sns.palplot(sns.color_palette(\"Spectral\", 10))\n",
    "sns.palplot(sns.color_palette(\"PRGn\", 10))\n",
    "sns.palplot(sns.color_palette(\"PiYG\", 10))\n",
    "sns.palplot(sns.color_palette(\"YlGnBu\", 10))\n",
    "sns.palplot(sns.color_palette(\"PuOr\", 10))\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically scrape IMDB.com\n",
    "# Returns a dictionary in the form of \n",
    "# {\"title\": [], \"genre\": [], \"imdb_score\": [], \"meta_score\": [], \"imdb_id\": [], \"year\": []}\n",
    "# Such that a DataFrame can be easily constructed\n",
    "def imdb_url_designer():\n",
    "    movies = {\"title\": [], \"genre\": [], \"imdb_score\": [], \"meta_score\": [], \"imdb_id\": [], \"year\": []}\n",
    "    url = None\n",
    "    for i in range(1, 10000, 50):\n",
    "        if i < 51:\n",
    "            url = \"https://www.imdb.com/search/title?title_type=movie&genres=action&explore=title_type,genres&ref_=adv_prv\"\n",
    "        if i > 50:\n",
    "            number = str(i)\n",
    "            url = \"https://www.imdb.com/search/title?title_type=movie&genres=action&start=\" + number + \"&explore=title_type,genres&ref_=adv_nxt\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            c = r.content\n",
    "            soup = BeautifulSoup(c, 'html.parser')\n",
    "            movie_articles = soup.find_all(\"div\", class_=\"lister-item mode-advanced\")\n",
    "            for movie_article in movie_articles:\n",
    "                # Regular Expression and compiler to extract the 4 digits of a year from the HTML \n",
    "                expression = \"(\\\\d+)\"\n",
    "                regex = re.compile(expression, re.IGNORECASE | re.DOTALL)\n",
    "                match = regex.search(movie_article.find(\"span\", class_=\"lister-item-year\").text)\n",
    "                if match:\n",
    "                    movie_year = int(match.group(1))\n",
    "                    if movie_year <= 2018:\n",
    "                        movies[\"year\"].append(movie_year) \n",
    "                        movie_name = movie_article.find(\"h3\", class_=\"lister-item-header\").a.text\n",
    "                        movies[\"title\"].append(movie_name)\n",
    "                        movie_genre = movie_article.find(\"span\", class_=\"genre\").text.strip().replace(\"/n\",\"\").split(\",\")\n",
    "                        movies[\"genre\"].append(movie_genre)\n",
    "                        movie_imdb_id = movie_article.find(\"div\", class_=\"ribbonize\")[\"data-tconst\"]\n",
    "                        movies[\"imdb_id\"].append(movie_imdb_id)\n",
    "                        movie_imdb_rating = movie_article.find(\"div\", class_=\"inline-block ratings-imdb-rating\")\n",
    "                        if movie_imdb_rating:\n",
    "                            movie_imdb_rating = movie_imdb_rating.text.strip().replace(\"/n\",\"\")\n",
    "                            movies[\"imdb_score\"].append(movie_imdb_rating) \n",
    "                        else:\n",
    "                            movies[\"imdb_score\"].append(\" \")                             \n",
    "                        movie_meta_rating = movie_article.find(\"span\", class_=\"metascore \")\n",
    "                        if movie_meta_rating:\n",
    "                            movie_meta_rating = movie_meta_rating.text.strip()\n",
    "                            movies[\"meta_score\"].append(movie_meta_rating)\n",
    "                        else:\n",
    "                            movies[\"meta_score\"].append(\" \")\n",
    "        else:\n",
    "            print(r.status_code)\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the returned dictionary into a Pandas DataFrame\n",
    "imdb_df = pd.DataFrame.from_dict(movies_dictionary)\n",
    "# Save DataFrame to csv\n",
    "imdb_df.to_csv(r\"/Users/.../imdb_movies_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically make API requests to TMDb.org,\n",
    "# Using the IMDB.com ids, in order to retrieve the movie ids \n",
    "# Used by this website to make API requests\n",
    "# Using the headers recommended by the API documentation\n",
    "# To prevent from going over the requests limits\n",
    "# Function does not return anything.\n",
    "def make_api_requests(movie_ids):\n",
    "    api_key = {api_key_tmdb}\n",
    "    for idx, movie in enumerate(movie_ids):\n",
    "        if movie[\"tmdb_id\"] == None:\n",
    "            url = \"https://api.themoviedb.org/3/find/\" + movie[\"imdb_id\"] + \"?api_key=\" + api_key + \"&language=en-US&external_source=imdb_id\"\n",
    "            r = requests.get(url)\n",
    "            if r.status_code == 200:\n",
    "                try:\n",
    "                    # X-RateLimit-Remaining is a header specified in the API documentation\n",
    "                    # To keep track of requests and not go over the maximum\n",
    "                    limit_remaining = int(r.headers['X-RateLimit-Remaining'])\n",
    "                except KeyError as e:\n",
    "                    print(f\"KeyError: {str(e)}\")\n",
    "                    print(f\"Response: {r}\")\n",
    "                    print(f\"Headers: {r.headers}\")\n",
    "                # X-RateLimit-Reset is a header specified in the API documentation\n",
    "                # To keep track of how many seconds until the limit resets again    \n",
    "                reset_time = int(r.headers['X-RateLimit-Reset'])\n",
    "                result = r.json()\n",
    "                if result[\"movie_results\"]:\n",
    "                    print(f\"\\r{idx}\", end = \"\")\n",
    "                    movie[\"tmdb_id\"] = result[\"movie_results\"][0][\"id\"]\n",
    "                else:\n",
    "                    print(\"Result came back empty for id: \" + movie[\"imdb_id\"])\n",
    "            else:\n",
    "                print(r.status_code)\n",
    "            while limit_remaining == 2 and reset_time > time.time():\n",
    "                print(\"Limit reached, waiting...\\r\", end = \"\")\n",
    "                time.sleep(1)\n",
    "            print(f\"  \", end = \"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of TMDB movie ids.\n",
    "movie_ids = list(map(lambda imdb_id : {\"imdb_id\": imdb_id, \"tmdb_id\": None }, movies_dictionary[\"imdb_id\"]))\n",
    "make_api_requests(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the returned dictionary into a Pandas DataFrame\n",
    "movie_ids_df = pd.DataFrame.from_dict(movie_ids)\n",
    "# Save DataFrame to csv\n",
    "movie_ids_df.to_csv(r\"/Users/.../movie_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a dictionary of movie ids, and dynamically\n",
    "# Makes requests to TMDB API. This is a mutating function\n",
    "# That transforms a en empty dictionary, into a dictionary\n",
    "# With information from the movies requested\n",
    "def make_movie_api_requests(movies_dict):\n",
    "    api_key = {api_key_tmbd} \n",
    "    for idx, m_id in enumerate(movies_dict['id']):\n",
    "        if movies_dict[\"title\"][idx] == None:\n",
    "            m_id = str(m_id)\n",
    "            url = \"https://api.themoviedb.org/3/movie/\" + m_id + \"?api_key=\" + api_key + \"&language=en-US\"\n",
    "            r = requests.get(url)\n",
    "            if r.status_code == 200:\n",
    "                try:\n",
    "                    # X-RateLimit-Remaining is a header specified in the API documentation\n",
    "                    # To keep track of requests and not go over the maximum\n",
    "                    limit_remaining = int(r.headers['X-RateLimit-Remaining'])\n",
    "                    # X-RateLimit-Reset is a header specified in the API documentation\n",
    "                    # To keep track of how many seconds until the limit resets again\n",
    "                    reset_time = int(r.headers['X-RateLimit-Reset'])\n",
    "                except KeyError as e:\n",
    "                    print(f\"KeyError: {str(e)}\")\n",
    "                    print(f\"Response: {r}\")\n",
    "                    print(f\"Headers: {r.headers}\")\n",
    "                result = r.json()\n",
    "                print(\"\\r\", idx, end = '')\n",
    "                if result[\"title\"]:\n",
    "                    movies_dict[\"title\"][idx] = result[\"title\"]\n",
    "                else:\n",
    "                    movies_dict[\"title\"][idx] = result[\"title\"]\n",
    "                if result[\"budget\"]:\n",
    "                    movies_dict[\"budget\"].append(result[\"budget\"])\n",
    "                else:\n",
    "                    movies_dict[\"budget\"].append(np.nan)\n",
    "\n",
    "                if result[\"belongs_to_collection\"]:\n",
    "                    movies_dict[\"belongs_to_collection\"].append(result[\"belongs_to_collection\"][\"name\"])\n",
    "                else:\n",
    "                    movies_dict[\"belongs_to_collection\"].append(np.nan) \n",
    "\n",
    "                if result[\"genres\"]:\n",
    "                    movies_dict[\"genres\"].append(list(map(lambda genre: genre[\"name\"], result[\"genres\"])))\n",
    "                else:\n",
    "                    movies_dict[\"genres\"].append(np.nan)\n",
    "\n",
    "                if result[\"imdb_id\"]:\n",
    "                    movies_dict[\"imdb_id\"].append(result[\"imdb_id\"])\n",
    "                else:\n",
    "                    movies_dict[\"imdb_id\"].append(np.nan)\n",
    "\n",
    "                if result[\"overview\"]:\n",
    "                    movies_dict[\"overview\"].append(result[\"overview\"])\n",
    "                else:\n",
    "                    movies_dict[\"overview\"].append(np.nan)\n",
    "\n",
    "                if result[\"tagline\"]:\n",
    "                    movies_dict[\"tagline\"].append(result[\"tagline\"])\n",
    "                else:\n",
    "                    movies_dict[\"tagline\"].append(np.nan)\n",
    "\n",
    "                if result[\"runtime\"]:\n",
    "                    movies_dict[\"runtime\"].append(result[\"runtime\"])\n",
    "                else:\n",
    "                    movies_dict[\"runtime\"].append(np.nan)\n",
    "\n",
    "                if result[\"revenue\"]:\n",
    "                    movies_dict[\"revenue\"].append(result[\"revenue\"])\n",
    "                else:\n",
    "                    movies_dict[\"revenue\"].append(np.nan)\n",
    "\n",
    "                if result[\"release_date\"]:\n",
    "                    movies_dict[\"release_date\"].append(result[\"release_date\"])\n",
    "                else:\n",
    "                    movies_dict[\"release_date\"].append(np.nan)\n",
    "\n",
    "                if result[\"production_companies\"]:\n",
    "                    movies_dict[\"production_companies\"].append(result[\"production_companies\"][0][\"name\"])\n",
    "                else:\n",
    "                    movies_dict[\"production_companies\"].append(np.nan)\n",
    "\n",
    "                if result[\"vote_count\"]:\n",
    "                    movies_dict[\"vote_count\"].append(result[\"vote_count\"])\n",
    "                else:\n",
    "                    movies_dict[\"vote_count\"].append(np.nan)\n",
    "\n",
    "                if result[\"vote_average\"]:\n",
    "                    movies_dict[\"vote_average\"].append(result[\"vote_average\"])\n",
    "                else:\n",
    "                    movies_dict[\"vote_average\"].append(np.nan)\n",
    "\n",
    "                if result[\"popularity\"]:\n",
    "                    movies_dict[\"popularity\"].append(result[\"popularity\"])\n",
    "                else:\n",
    "                    movies_dict[\"popularity\"].append(np.nan)\n",
    "            else:\n",
    "                print(r.status_code)\n",
    "            while limit_remaining == 2 and reset_time > time.time():\n",
    "                    print(\"Limit reached, waiting...\\r\", end = \"\")\n",
    "                    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the information of TMDB movies.\n",
    "tmdb_movies_dict = { \"id\": tmdb_ids.tolist(), \"title\": list(map(lambda el: None, tmdb_ids.tolist())), \"belongs_to_collection\": [], \"budget\": [], \"genres\": [], \"imdb_id\": [], \n",
    "           \"overview\": [], \"release_date\": [], \"revenue\": [], \"tagline\": [], \"release_date\": [],\n",
    "           \"vote_average\": [], \"vote_count\": [], \"runtime\": [], \"popularity\": [], \"production_companies\": [] }\n",
    "make_movie_api_requests(tmdb_movies_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the returned dictionary into a Pandas DataFrame\n",
    "tmdb_movies_df = pd.DataFrame.from_dict(tmdb_movies_dict)\n",
    "# Save DataFrame to csv\n",
    "tmdb_movies_df.to_csv(r\"/Users/.../tmdb_movies_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the crew csv file\n",
    "data_two = \"/Users/florencialeoni/Documents/flatironDS/Mod1/Blogpost_1/the-movies-dataset/credits.csv\"\n",
    "use_cols_two = [\"id\", \"cast\", \"crew\"]\n",
    "\n",
    "# Using pandas.read_csv method to load the file\n",
    "crew_df = pd.read_csv(data_two, usecols = use_cols_two)\n",
    "\n",
    "# Coerce the \"id\" column to numeric, drop the null values, and cast it as integer\n",
    "crew_df[\"id\"] = pd.to_numeric(crew_df[\"id\"], downcast = \"integer\", errors = \"coerce\")\n",
    "crew_df = crew_df.drop(crew_df[crew_df['id'].isnull()].index)\n",
    "crew_df[\"id\"] = crew_df[\"id\"].astype(int)\n",
    "\n",
    "# Converted both columns \"crew\" and \"cast\" to Abstract Syntax Trees,\n",
    "# Using Python's ast module and the .literal_eval() function, and\n",
    "# Applying it through the .apply() method. \n",
    "crew_df[\"crew\"] = crew_df[\"crew\"].apply(ast.literal_eval)\n",
    "crew_df[\"cast\"] = crew_df[\"cast\"].apply(ast.literal_eval)\n",
    "\n",
    "# Helper function to extract Directors' names from the recently parsed \"crew\" column\n",
    "def extract_director(crew_list):\n",
    "    for member in crew_list:\n",
    "        if member[\"department\"] == \"Directing\" and member[\"job\"] == \"Director\":\n",
    "            return member[\"name\"]\n",
    "crew_df[\"director_name\"] = crew_df[\"crew\"].map(extract_director)\n",
    "\n",
    "# Helper function to extract Directors' genders from the recently parsed \"crew\" column\n",
    "def extract_director_gender(crew_list):\n",
    "    for member in crew_list:\n",
    "        if member[\"department\"] == \"Directing\" and member[\"job\"] == \"Director\":\n",
    "            return member[\"gender\"]\n",
    "crew_df[\"director_gender\"] = crew_df[\"crew\"].map(extract_director_gender)\n",
    "\n",
    "#Helper function to extract Leading Actor from the recently parsed \"cast\" column\n",
    "def extract_leading_actor(cast_list):\n",
    "    for member in cast_list:\n",
    "        if member[\"order\"] == 0:\n",
    "            return member[\"name\"]\n",
    "crew_df[\"leading_actor_name\"] = crew_df[\"cast\"].map(extract_leading_actor)\n",
    "\n",
    "# Helper function to extract Supporting Actor from the recently parsed \"cast\" column\n",
    "def extract_supporting_actor(cast_list):\n",
    "    for member in cast_list:\n",
    "        if member[\"order\"] == 1:\n",
    "            return member[\"name\"]\n",
    "crew_df[\"supporting_actor_name\"] = crew_df[\"cast\"].map(extract_supporting_actor)\n",
    "\n",
    "# Drop the original \"cast\" and \"crew\" columns since we already have\n",
    "# The information we needed for the analysis.\n",
    "crew_df = crew_df.drop([\"cast\"], axis = 1)\n",
    "crew_df = crew_df.drop([\"crew\"], axis = 1)\n",
    "crew_df\n",
    "\n",
    "# Merge the main DataFrame with the crew DataFrame \n",
    "tmdb_movies_cast_df = pd.merge(tmdb_movies_df, crew_df, how='left', on=[\"id\"])\n",
    "\n",
    "# Set the \"id\" column as the Index for the DataFrame\n",
    "tmdb_movies_cast_df = tmdb_movies_cast_df.set_index(\"id\")\n",
    "\n",
    "# Save the DataFrame to a csv file\n",
    "tmdb_movies_cast_df.to_csv(r\"/Users/.../tmdb_movies_cast_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the IMDB movies file\n",
    "data = \"/Users/.../imdb_movies_data.csv\"\n",
    "use_cols = [\"imdb_id\", \"imdb_score\", \"meta_score\"]\n",
    "\n",
    "# Using pandas.read_csv method to load the file\n",
    "imdb_df = pd.read_csv(data, usecols = use_cols)\n",
    "imdb_df = imdb_df.set_index(\"imdb_id\")\n",
    "\n",
    "# Replace missing data in the \"imdb_score\" and \"meta_score\" columns with NumPy NaN values\n",
    "imdb_df[\"imdb_score\"] = imdb_df[\"imdb_score\"].replace(\" \", np.nan)\n",
    "imdb_df[\"meta_score\"] = imdb_df[\"meta_score\"].replace(\" \", np.nan)\n",
    "\n",
    "# Importing the TMDB Movies file\n",
    "data = \"/Users/.../tmdb_movies_cast_df.csv\"\n",
    "\n",
    "# Using pandas.read_csv method to load the file\n",
    "tmdb_df = pd.read_csv(data, lineterminator='\\n')\n",
    "tmdb_df = tmdb_df.set_index(\"id\")\n",
    "tmdb_df = tmdb_df.merge(imdb_df, how = \"left\", on = \"imdb_id\")\n",
    "\n",
    "# Using pandas.to_numeric to coerce the \"id\", \"budget\" and \"revenue\" columns into numbers\n",
    "tmdb_df[\"budget\"] = pd.to_numeric(tmdb_df[\"budget\"], downcast = \"integer\", errors = \"coerce\")\n",
    "tmdb_df[\"revenue\"] = pd.to_numeric(tmdb_df[\"revenue\"], downcast = \"integer\", errors = \"coerce\")\n",
    "\n",
    "# Lambda function to strip and split \"release_date\" string values\n",
    "f = lambda x: str(x).strip().split('-')[0] if x != np.nan else np.nan\n",
    "\n",
    "# Creating a new column, \"year\", and assigninf the value of \"release_date\" \n",
    "# After applying the lambda function through map\n",
    "tmdb_df[\"year\"] = tmdb_df[\"release_date\"].map(f)\n",
    "\n",
    "# Coerce the \"year\" column to integers\n",
    "tmdb_df[\"year\"] = pd.to_numeric(tmdb_df[\"year\"], errors = \"coerce\")\n",
    "\n",
    "# Convert \"release_date\" column to datetime format\n",
    "tmdb_df[\"release_date\"] = pd.to_datetime(tmdb_df[\"release_date\"])\n",
    "\n",
    "# Divide \"release_date\" column in months\n",
    "tmdb_df[\"month_of_year\"] = tmdb_df[\"release_date\"].dt.month_name()\n",
    "\n",
    "# Divide \"release_date\" column in months\n",
    "tmdb_df[\"day_of_week\"] = tmdb_df[\"release_date\"].dt.day_name()\n",
    "\n",
    "# Create a subset of the main DataFrame focused on genres\n",
    "genres_df = tmdb_df[tmdb_df[\"genres\"].notnull()][[\"title\",\"budget\", \"revenue\", \"runtime\", \"year\", \n",
    "                        \"month_of_year\", \"day_of_week\", \"popularity\", \"imdb_score\", \"meta_score\", \"genres\"]]\n",
    "\n",
    "# Unpack the values in the genre column using the ast module\n",
    "genres_df[\"genres\"] = genres_df[\"genres\"].apply(ast.literal_eval)\n",
    "\n",
    "# Add a column to account for each genre of each movie to the genres_df subset\n",
    "genres = genres_df[\"genres\"]\n",
    "genres = genres.apply(pd.Series)\n",
    "genres = genres.rename(columns = lambda x : 'genre_' + str(x))\n",
    "genres_df = pd.concat([genres_df[:], genres[:]], axis=1)\n",
    "\n",
    "# Drop the release date column as we have extracted its information\n",
    "tmdb_df = tmdb_df.drop([\"release_date\"], axis=1)\n",
    "\n",
    "# Create a subset of the main DataFrame focused on the revenue\n",
    "tmdb_df_revenue = tmdb_df[tmdb_df[\"revenue\"].notnull()][[\"title\", \"budget\", \"revenue\", \"year\", \n",
    "                        \"month_of_year\", \"day_of_week\", \"popularity\", \"imdb_score\", \"meta_score\", \n",
    "                            \"production_companies\", \"director_name\", \"leading_actor_name\"]]\n",
    "\n",
    "# Drop columns for which budget is a null value\n",
    "tmdb_df_revenue = tmdb_df_revenue.dropna(subset=[\"budget\"])\n",
    "\n",
    "# Create a new column to hold the value of the ROI\n",
    "tmdb_df_revenue[\"roi\"] = ((tmdb_df_revenue[\"revenue\"] - tmdb_df_revenue[\"budget\"]) / tmdb_df_revenue[\"budget\"])\n",
    "\n",
    "# Drop the numbers that are too small\n",
    "tmdb_df_revenue = tmdb_df_revenue.drop(tmdb_df_revenue[tmdb_df_revenue.budget < 5000].index)\n",
    "tmdb_df_revenue = tmdb_df_revenue.drop(tmdb_df_revenue[tmdb_df_revenue.revenue < 5000].index)\n",
    "\n",
    "# Subset of less popular movies\n",
    "less_popular = tmdb_df[tmdb_df[\"popularity\"].notnull()][[\"title\", \"tagline\", \n",
    "                        \"popularity\", \"year\", \"overview\", \"director_name\", \n",
    "                        \"leading_actor_name\", \"supporting_actor_name\", \"budget\"]].sort_values(\"popularity\").head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a new SQLite3 Database\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Use create_connection function to create Database\n",
    "create_connection(\"/Users/.../movies.db\")\n",
    "\n",
    "# Create a connection object using the connect function \n",
    "# To establish a connection with \"movies.db\"\n",
    "connection = sqlite3.connect(\"movies.db\")\n",
    "# Create a cursor object by calling the cursor method\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Write records stored in the imdb_df DataFrame to a SQL database\n",
    "imdb_df.to_sql(\"imdb_movies\", con = connection)\n",
    "\n",
    "# Write records stored in the tmdb_df DataFrame to a SQL database\n",
    "tmdb_df.to_sql(\"tmdb_movies\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join of IMDB table and TMDB table\n",
    "combined_df = pd.read_sql_query('''\n",
    "SELECT\n",
    "    id,\n",
    "    title, \n",
    "    belongs_to_collection, \n",
    "    budget, \n",
    "    genres,\n",
    "    overview, \n",
    "    revenue, \n",
    "    tagline, \n",
    "    director_name,\n",
    "    leading_actor_name,\n",
    "    supporting_actor_name,\n",
    "    vote_average, \n",
    "    vote_count, \n",
    "    runtime, \n",
    "    popularity, \n",
    "    production_companies,\n",
    "    year,\n",
    "    month_of_year,\n",
    "    day_of_week,\n",
    "    tmdb_movies.imdb_id AS tmdb_imdb_id,\n",
    "    imdb_movies.imdb_id AS imdb_id,\n",
    "    imdb_score\n",
    "    meta_score\n",
    "FROM\n",
    "    tmdb_movies\n",
    "    INNER JOIN imdb_movies ON tmdb_movies.imdb_id = imdb_movies.imdb_id;''', connection)\n",
    "\n",
    "# Querying the database\n",
    "pd.read_sql_query('''SELECT title, MAX(popularity) FROM tmdb_movies''', connection)\n",
    "pd.read_sql_query('''SELECT title, MAX(revenue) FROM tmdb_movies''', connection)\n",
    "pd.read_sql_query('''SELECT title, MAX(budget) FROM tmdb_movies''', connection)\n",
    "pd.read_sql_query('''SELECT title, MIN(budget) FROM tmdb_movies''', connection)\n",
    "pd.read_sql_query('''SELECT title, MIN(popularity) FROM tmdb_movies''', connection)\n",
    "pd.read_sql_query('''SELECT title, revenue, budget, vote_count, year, genres, popularity FROM tmdb_movies \n",
    "                    WHERE production_companies LIKE \"%lionsgate%\";''', connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
